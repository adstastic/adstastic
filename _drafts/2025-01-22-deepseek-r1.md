---
layout: post
title: DeepSeek r1
tags: [ai, machine-learning, tech]
---

DeepSeek open-sourced a series of reasoning models under the `r1` umbrella recently.
This is very exciting, because it's the first openly available reasoning model that compares to OpenAI's `o1` in evals.
I downloaded a bunch of them to test locally, with the famous "strawberry" problem: _Count the number of r's in 'strawberry'_ 

Changes to the prompt can have a signficant impact on output, so I tried the following variations to determine that effect, as well as mitigate its influence in the aggregate results:
```json
{
    "base": "Count the number of r's in strawberry",
    "incorrect": "Count the number of r's in strawberry. 2 is the incorrect answer.",
    "logical": "Count the number of r's in strawberry. Be logical",
    "fullstop": "Count the number of r's in strawberry.",
    "word_fullstop": "Count the number of r's in the word strawberry.",
    "explicit": "Count the number of times the letter 'r' appears in the word 'strawberry'",
    "question": "How many r's are there in strawberry?",
    "question_quote": "How many r's are there in 'strawberry'?",
    "question_explicit": "How many times does the letter 'r' appear in the word 'strawberry'?"
} 
```
I ran each of these prompts at least[^at-least] 13 times for each of the model variants that would fit in my M3 Macbook Pro's 128GB memory.
- deepseek-r1:70b
- deepseek-r1:32b
- deepseek-r1:14b
- deepseek-r1:8b
- deepseek-r1:7b
- deepseek-r1:1.5b

[^at-least]: I ran my eval scripts often during development to debug them so some models have more data points.

I wrote a script to run this using Simon Wilison's excellent [llm](https://llm.datasette.io/en/stable/) tool to log all data and stats about the responses[^llm-ollama], as I wanted to compare how many reasoning tokens it took each model to get to an answer, whether it was correct, and the effect of tweaking the prompt slightly.

[^llm-ollama]: I went on a [side-quest](https://github.com/taketwo/llm-ollama/pull/30) to implement the [token usage mechanism](https://llm.datasette.io/en/stable/plugins/advanced-model-plugins.html#tracking-token-usage) LLM exposes in the [llm-ollama](https://github.com/taketwo/llm-ollama) plugin

## Results




